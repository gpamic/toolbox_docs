{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Multi-Layer Perceptron Classifier</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "\n",
    "2. [Using the Classifier](#using_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multi-layer Perceptron (MLP) algorithm..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using the classifier <a class=\"anchor\" id=\"using_classifier\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the toolbox and its modules from the parent folder\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from toolbox.learning.neural_networks.supervised.models.mlp import MultiLayerPerceptron\n",
    "from toolbox.preprocessing.encoding import dummie2multilabel\n",
    "from toolbox.evaluation.classifiers import confusion_matrix, compute_indices\n",
    "\n",
    "# Import Auxiliary Libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples, Attributes and Classes:\n",
      "1078 64 10\n",
      "(1078, 64)\n",
      "(1078, 1)\n",
      "(719, 64)\n",
      "(719, 1)\n",
      "(1078, 10)\n",
      "(719, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# DataSet\n",
    "\n",
    "# Import digits recognition dataset (from sklearn)\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.4, random_state=2020)\n",
    "\n",
    "# Scaling features (from sklearn)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_norm = scaler.transform(X_tr)\n",
    "X_ts_norm = scaler.transform(X_ts)\n",
    "\n",
    "# Get number of attributes and classes\n",
    "\n",
    "p = X_tr.shape[1]\n",
    "n_samples_tr = X_tr.shape[0]\n",
    "n_samples_ts = X_ts.shape[0]\n",
    "n_classes = len(np.unique(y_tr))\n",
    "\n",
    "# Reshape outputs\n",
    "\n",
    "y_tr = y_tr.reshape((n_samples_tr,1))\n",
    "y_ts = y_ts.reshape((n_samples_ts,1))\n",
    "\n",
    "y_tr2 = np.zeros((n_samples_tr,n_classes))\n",
    "y_ts2 = np.zeros((n_samples_ts,n_classes))\n",
    "\n",
    "for i in range(n_samples_tr):\n",
    "    y_tr2[i,y_tr[i]] = 1\n",
    "for i in range(n_samples_ts):\n",
    "    y_ts2[i,y_ts[i]] = 1\n",
    "\n",
    "print('Number of Samples, Attributes and Classes:')\n",
    "print(n_samples_tr,p,n_classes)\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "print(X_ts.shape)\n",
    "print(y_ts.shape)\n",
    "print(y_tr2.shape)\n",
    "print(y_ts2.shape)\n",
    "print(y_tr2[0:5,:])\n",
    "print(y_ts2[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP CLassifier\n",
    "\n",
    "NPL = [p, 4, n_classes]\n",
    "\n",
    "mlp = MultiLayerPerceptron()\n",
    "\n",
    "mlp.fit(X=X_tr_norm, Y=y_tr2, Xv=X_tr, Yv=y_tr2, NPL=NPL, epochs=20, n_batches=1, \n",
    "        alpha=1e-2, decay=0, momentum=0, l2=0, dropout_percent=0)\n",
    "\n",
    "y_mlp = mlp.predict(X_ts)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.44326405e-012 3.01497419e-032 3.21931740e-044 1.00587856e-041\n",
      "  1.00000000e+000]\n",
      " [4.59001630e-078 8.92628838e-147 9.40758924e-070 1.00000000e+000\n",
      "  4.41917680e-203]\n",
      " [1.12484884e-051 1.15480513e-144 1.67969630e-150 3.16511851e-096\n",
      "  2.63327718e-070]\n",
      " ...\n",
      " [1.51007312e-021 7.65141296e-037 7.12987827e-044 1.67963032e-052\n",
      "  1.81262908e-009]\n",
      " [1.00000000e+000 5.36663760e-159 6.08503706e-051 3.76364974e-026\n",
      "  3.18528991e-128]\n",
      " [8.15123172e-036 3.09793473e-037 1.76371690e-068 2.03245703e-020\n",
      "  1.50666607e-029]]\n"
     ]
    }
   ],
   "source": [
    "print(y_mlp[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
